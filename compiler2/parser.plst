import iter
import json

import lex
import ts
import expr

enum IfTail
    end_ |
    else_(Block) |
    elsif_(expr.Expression, Block, IfTail)
end

enum Statement
    assignment(String, expr.Expression) |
    if_(expr.Expression, Block, IfTail)
end

enum Terminator
    return_(expr.Expression) |
    throw_(expr.Expression) |
    no_terminator
end

enum Block
    block(List(Statement), Terminator)
end

enum ServiceDecl
    attr_(String, Type) |
    private_ |
    implements_
end

enum TopLevel
    record_ |
    enum_(String, List((String, List(Type)))) |
    service_(String, List((String, Type)), List(ServiceDecl)) |
    entry_(Block) |
    function_(String, List((String, Type)), Type, Block) |
    coroutine_(String, List((String, Type)), Type, Type, Block)
end

enum Type
    named_type(ts.MaybeString, String)
end

define parse_imports(tokens : List(lex.Token)) -> (List(String), List(lex.Token)) do
    imports := [] : (List(String));
    do
        if (tokens.length() > 0)
            k := ts.peek_keyword(tokens);
            match (k)
                just_string(k1) do
                    if (k1 == "import")
                        name, tokens := ts.assert_is_lower_name(tokens.drop(1));
                        imports := imports.append(name);
                    else
                        return (imports, tokens);
                    end
                end
                nothing_string do
                    return (imports, tokens);
                end
            end
        end
    while (true)
    throw void;
end

define parse_type(tokens : List(lex.Token)) -> (Type, List(lex.Token)) do
    match (tokens.index(0))
        lower_name(module) do
            tokens := ts.assert_symbol(tokens.drop(1), ".");
            name, tokens := ts.assert_is_upper_name(tokens);
            return (named_type(ts.just_string(module), name), tokens);
        end
        upper_name(name) do
            return (named_type(ts.nothing_string(), name), tokens.drop(1));
        end
    end
end

define parse_parameter(tokens : List(lex.Token)) -> (String, Type, List(lex.Token)) do
    name, tokens := ts.assert_is_lower_name(tokens);
    tokens := ts.assert_symbol(tokens, ":");
    type, tokens := parse_type(tokens);
    return (name, type, tokens);
end

define parse_parameter_list(tokens : List(lex.Token)) -> (List((String, Type)), List(lex.Token)) do
    tokens := ts.assert_symbol(tokens, "(");
    parameters := [] : (List((String, Type)));
    do
        token := tokens.index(0);
        match (token)
            lower_name(name) do
                name, type, tokens := parse_parameter(tokens);
                parameters := parameters.append((name, type));
            end
            symbol(s) do
                tokens := ts.assert_symbol(tokens, ")");
                return (parameters, tokens);
            end
        end
    while(true)
    throw void;
end

define parse_if_tail(tokens : List(lex.Token)) -> (IfTail, List(lex.Token)) do
    k, tokens := ts.assert_is_keyword(tokens);
    if (k == "end")
        return (end_(), tokens);
    elsif (k == "else")
        block, tokens := parse_code_block(tokens);
        tokens := ts.assert_keyword(tokens, "end");
        return (else_(block), tokens);
    elsif (k == "elsif")
        tokens := ts.assert_symbol(tokens, "(");
        exp, tokens := expr.parse_expression(tokens);
        tokens := ts.assert_symbol(tokens, ")");
        block, tokens := parse_code_block(tokens);
        tail, tokens := parse_if_tail(tokens);
        return (elsif_(exp, block, tail), tokens);
    end
    throw void;
end

define parse_if(tokens : List(lex.Token)) -> (Statement, List(lex.Token)) do
    tokens := ts.assert_keyword(tokens, "if");
    tokens := ts.assert_symbol(tokens, "(");
    exp, tokens := expr.parse_expression(tokens);
    tokens := ts.assert_symbol(tokens, ")");
    block, tokens := parse_code_block(tokens);
    tail, tokens := parse_if_tail(tokens);
    return (if_(exp, block, tail), tokens);
end

define parse_do(tokens : List(lex.Token)) -> (Statement, List(lex.Token)) do
    throw void;
end

define parse_while(tokens : List(lex.Token)) -> (Statement, List(lex.Token)) do
    throw void;
end

define parse_for(tokens : List(lex.Token)) -> (Statement, List(lex.Token)) do
    throw void;
end

define parse_match(tokens : List(lex.Token)) -> (Statement, List(lex.Token)) do
    throw void;
end

define parse_code_block(tokens : List(lex.Token)) -> (Block, List(lex.Token)) do
    statements := [] : (List(Statement));
    do
        k := ts.peek_keyword(tokens);
        match (k)
            just_string(k1) do
                if (k1 == "if")
                    statement, tokens := parse_if(tokens);
                    statements := statements.append(statement);
                elsif (k1 == "do")
                    statement, tokens := parse_do(tokens);
                    statements := statements.append(statement);
                elsif (k1 == "while")
                    statement, tokens := parse_while(tokens);
                    statements := statements.append(statement);
                elsif (k1 == "for")
                    statement, tokens := parse_for(tokens);
                    statements := statements.append(statement);
                elsif (k1 == "match")
                    statement, tokens := parse_match(tokens);
                    statements := statements.append(statement);
                else
                    return (block(statements, no_terminator()), tokens);
                end
            end
            nothing_string do
                return (block(statements, no_terminator()), tokens);
            end
        end
    while (true)
    throw void;
end

define parse_function(tokens : List(lex.Token)) -> (TopLevel, List(lex.Token)) do
    tokens := ts.assert_keyword(tokens, "define");
    name, tokens := ts.assert_is_lower_name(tokens);
    parameter_list, tokens := parse_parameter_list(tokens);
    tokens := ts.assert_symbol(tokens, "->");
    return_type, tokens := parse_type(tokens);
    tokens := ts.assert_keyword(tokens, "do");
    code_block, tokens := parse_code_block(tokens);
    tokens := ts.assert_keyword(tokens, "end");
    return (function_(name, parameter_list, return_type, code_block), tokens);
end

define parse_coroutine(tokens : List(lex.Token)) -> (TopLevel, List(lex.Token)) do
    tokens := ts.assert_keyword(tokens, "coroutine");
    name, tokens := ts.assert_is_lower_name(tokens);
    parameter_list, tokens := parse_parameter_list(tokens);
    receive_type, tokens := parse_type(tokens);
    tokens := ts.assert_symbol(tokens, "->");
    yield_type, tokens := parse_type(tokens);
    tokens := ts.assert_keyword(tokens, "do");
    code_block, tokens := parse_code_block(tokens);
    tokens := ts.assert_keyword(tokens, "end");
    return (coroutine_(name, parameter_list, receive_type, yield_type, code_block), tokens);
end

define parse_enum(tokens : List(lex.Token)) -> (TopLevel, List(lex.Token)) do
    tokens := ts.assert_keyword(tokens, "enum");
    throw void;
end

define parse_record(tokens : List(lex.Token)) -> (TopLevel, List(lex.Token)) do
    tokens := ts.assert_keyword(tokens, "record");
    throw void;
end

define parse_interface(tokens : List(lex.Token)) -> (TopLevel, List(lex.Token)) do
    tokens := ts.assert_keyword(tokens, "interface");
    throw void;
end

define parse_dependency(tokens : List(lex.Token)) -> (String, Type, List(lex.Token)) do
    name, tokens := ts.assert_is_lower_name(tokens);
    tokens := ts.assert_symbol(tokens, ":");
    type, tokens := parse_type(tokens);
    return (name, type, tokens);
end

define parse_dependencies(tokens : List(lex.Token)) -> (List((String, Type)), List(lex.Token)) do
    throw void;
end

define parse_service_decls(tokens : List(lex.Token)) -> (List(ServiceDecl), List(lex.Token)) do
    throw void;
end

define parse_service(tokens : List(lex.Token)) -> (TopLevel, List(lex.Token)) do
    tokens := ts.assert_keyword(tokens, "service");
    name, tokens := ts.assert_is_upper_name(tokens);
    dependencies, tokens := parse_dependencies(tokens);
    decls, tokens := parse_service_decls(tokens);
    tokens := ts.assert_keyword(tokens, "end");
    return (service_(name, dependencies, decls), tokens);
end

define parse_entry(tokens : List(lex.Token)) -> (TopLevel, List(lex.Token)) do
    tokens := ts.assert_keyword(tokens, "entry");
    code_block, tokens := parse_code_block(tokens);
    tokens := ts.assert_keyword(tokens, "end");
    return (entry_(code_block), tokens);
end

define parse(tokens : List(lex.Token)) -> (List(String), List(TopLevel)) do
    imports, tokens := parse_imports(tokens);
    decls := [] : (List(TopLevel));
    do
        if (tokens.length() == 0)
            return (imports, decls);
        end

        token := tokens.index(0);
        match (token)
            keyword(key) do
                if (key == "define")
                    decl, tokens := parse_function(tokens);
                    decls := decls.append(decl);
                elsif (key == "coroutine")
                    decl, tokens := parse_coroutine(tokens);
                    decls := decls.append(decl);
                elsif (key == "enum")
                    decl, tokens := parse_enum(tokens);
                    decls := decls.append(decl);
                elsif (key == "record")
                    decl, tokens := parse_record(tokens);
                    decls := decls.append(decl);
                elsif (key == "interface")
                    decl, tokens := parse_interface(tokens);
                    decls := decls.append(decl);
                elsif (key == "service")
                    decl, tokens := parse_service(tokens);
                    decls := decls.append(decl);
                elsif (key == "entry")
                    decl, tokens := parse_entry(tokens);
                    decls := decls.append(decl);
                else
                    throw void;
                end
            end
        end
    while (true)
end

service Test(
            f : file.FileOps
        )
    constructor new()
    end

    implements EntryPoint
        define main() -> Bool do
            fd := @f.open("input.plst".encode_utf8(), 0);
            source := @f.read(fd, 4096).decode_utf8();
            if (source.length() == 4096)
                throw void;
            end
            @f.close(fd);
            debug("lexing");
            tokens := lex.lex(source);
            debug("lexed");
            imports, decls := parse(tokens);
            debug(("parsed", decls));
            return true;
        end
    end
end

entry
    f := file.SysFileOps().new();
    return Test(f).new();
end
